# --- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any
import logging
import openai
from geopy.distance import great_circle
import datetime
import json
from dotenv import load_dotenv
from gensim.models import Word2Vec
load_dotenv()

# --- 2. í”„ë¡œì íŠ¸ ì„¤ì • ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG = {
    "store_db_path": os.path.join(BASE_DIR, "data", "stores_with_preferences_vec.csv"),
    "w2v_model_path": os.path.join(BASE_DIR, "data", "w2v_activity_model.model"),
}
assets = {}  # ì „ì—­ ë³€ìˆ˜ë¡œ ë°ì´í„° ì €ì¥

CATEGORY_MAPPING = {
    # --- ğŸš í•œì‹ ---
    'í•œì‹': 'í•œì‹',
    'êµ­ë°¥': 'í•œì‹',
    'ê³°íƒ•': 'í•œì‹',
    'ì„¤ë íƒ•': 'í•œì‹',
    'ì°Œê°œ,ì „ê³¨': 'í•œì‹',
    'í•´ì¥êµ­': 'í•œì‹',
    'ê°ìíƒ•': 'í•œì‹',
    'ì‚¼ê³„íƒ•': 'í•œì‹',
    'í•œì •ì‹': 'í•œì‹',
    'ìŒˆë°¥': 'í•œì‹',
    'ë‘ë¶€ì „ë¬¸ì ': 'í•œì‹',
    'ê¸°ì‚¬ì‹ë‹¹': 'í•œì‹',
    # --- ğŸ¥© ê³ ê¸°ìš”ë¦¬ ---
    'ìœ¡ë¥˜,ê³ ê¸°': 'ê³ ê¸°ìš”ë¦¬',
    'ê³ ê¸°ìš”ë¦¬': 'ê³ ê¸°ìš”ë¦¬',
    'ì‚¼ê²¹ì‚´': 'ê³ ê¸°ìš”ë¦¬',
    'ê°ˆë¹„': 'ê³ ê¸°ìš”ë¦¬',
    'ë¶ˆê³ ê¸°,ë‘ë£¨ì¹˜ê¸°': 'ê³ ê¸°ìš”ë¦¬',
    'ì¡±ë°œ,ë³´ìŒˆ': 'ê³ ê¸°ìš”ë¦¬',
    'ê³±ì°½,ë§‰ì°½': 'ê³ ê¸°ìš”ë¦¬',
    'ê³ ê¸°ë·”í˜': 'ë¶€í˜',
    'ì‚¬ì² íƒ•,ì˜ì–‘íƒ•': 'ê³ ê¸°ìš”ë¦¬',
    # --- ğŸ— ë‹­/ì˜¤ë¦¬ìš”ë¦¬ ---
    'ë‹­ìš”ë¦¬': 'ë‹­/ì˜¤ë¦¬ìš”ë¦¬',
    'ë‹­/ì˜¤ë¦¬ìš”ë¦¬': 'ë‹­/ì˜¤ë¦¬ìš”ë¦¬',
    'ë‹­ê°•ì •': 'ë‹­/ì˜¤ë¦¬ìš”ë¦¬',
    'ì¹˜í‚¨': 'ë‹­/ì˜¤ë¦¬ìš”ë¦¬',
    'ì˜¤ë¦¬': 'ë‹­/ì˜¤ë¦¬ìš”ë¦¬',
    # --- ğŸ£ ì¤‘ì‹/ì¼ì‹/ì–‘ì‹/ê¸°íƒ€ êµ­ê°€ ---
    'ì¤‘ì‹': 'ì¤‘ì‹',
    'ì¤‘êµ­ìš”ë¦¬': 'ì¤‘ì‹',
    'ì¼ì‹': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì¼ì‹ì§‘': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì¼ì‹/ìˆ˜ì‚°ë¬¼': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì´ˆë°¥,ë¡¤': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì°¸ì¹˜íšŒ': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'íšŒ': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'í•´ë¬¼,ìƒì„ ': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ëˆê¹ŒìŠ¤,ìš°ë™': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì¼ë³¸ì‹ë¼ë©´': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'í“¨ì „ì¼ì‹': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì¡°ê°œ': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ê²Œ,ëŒ€ê²Œ': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì¥ì–´': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì•„êµ¬': 'ì¼ì‹/ìˆ˜ì‚°ë¬¼',
    'ì¶”ì–´': 'í•œì‹',
    'ì–‘ì‹': 'ì–‘ì‹',
    'ì´íƒˆë¦¬ì•ˆ': 'ì–‘ì‹',
    'í”„ë‘ìŠ¤ìŒì‹': 'ì–‘ì‹',
    'ìŠ¤í…Œì´í¬,ë¦½': 'ì–‘ì‹',
    'íŒ¨ë°€ë¦¬ë ˆìŠ¤í† ë‘': 'ì–‘ì‹',
    'ë² íŠ¸ë‚¨ìŒì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'íƒœêµ­ìŒì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'ë™ë‚¨ì•„ìŒì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'ë©•ì‹œì¹¸,ë¸Œë¼ì§ˆ': 'ë³„ì‹/í“¨ì „ìš”_ë¦¬',
    'ìŠ¤í˜ì¸ìŒì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'ì¸ë„ìŒì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'ì•„ì‹œì•„ìŒì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'í“¨ì „ìš”ë¦¬': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'ë³„ì‹/í“¨ì „ìš”ë¦¬': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    'í“¨ì „í•œì‹': 'ë³„ì‹/í“¨ì „ìš”ë¦¬',
    # --- â˜• ì¹´í˜/ë””ì €íŠ¸/ì£¼ì  ---
    'ì¹´í˜': 'ì»¤í”¼/ìŒë£Œ',
    'ì»¤í”¼/ìŒë£Œ': 'ì»¤í”¼/ìŒë£Œ',
    'ì»¤í”¼ì „ë¬¸ì ': 'ì»¤í”¼/ìŒë£Œ',
    'ë””ì €íŠ¸ì¹´í˜': 'ì»¤í”¼/ìŒë£Œ',
    'ë¶ì¹´í˜': 'ì·¨ë¯¸/ì˜¤ë½',
    'ê°¤ëŸ¬ë¦¬ì¹´í˜': 'ì „ì‹œì¥',
    'í‚¤ì¦ˆì¹´í˜': 'ì·¨ë¯¸/ì˜¤ë½',
    'í…Œë§ˆì¹´í˜': 'ì»¤í”¼/ìŒë£Œ',
    'ë‹¤ë°©': 'ì»¤í”¼/ìŒë£Œ',
    'ì „í†µì°»ì§‘': 'ì»¤í”¼/ìŒë£Œ',
    'ìŒì•…ê°ìƒì‹¤': 'ì·¨ë¯¸/ì˜¤ë½',
    'ì œê³¼,ë² ì´ì»¤ë¦¬': 'ì œê³¼/ì œë¹µ/ë–¡/ì¼€ìµ',
    'ì œê³¼/ì œë¹µ/ë–¡/ì¼€ìµ': 'ì œê³¼/ì œë¹µ/ë–¡/ì¼€ìµ',
    'ë„ë„›': 'ì œê³¼/ì œë¹µ/ë–¡/ì¼€ìµ',
    'ì•„ì´ìŠ¤í¬ë¦¼': 'ì œê³¼/ì œë¹µ/ë–¡/ì¼€ìµ',
    'ì•„ì´ìŠ¤í¬ë¦¼íŒë§¤': 'ì œê³¼/ì œë¹µ/ë–¡/ì¼€ìµ',
    'ìœ í¥ì£¼ì ': 'ìœ í¥ì£¼ì ',
    'ì¼ë³¸ì‹ì£¼ì ': 'ìœ í¥ì£¼ì ',
    'ì‹¤ë‚´í¬ì¥ë§ˆì°¨': 'ìœ í¥ì£¼ì ',
    'í˜¸í”„,ìš”ë¦¬ì£¼ì ': 'ìœ í¥ì£¼ì ',
    'ìˆ ì§‘': 'ìœ í¥ì£¼ì ',
    'ì¹µí…Œì¼ë°”': 'ìœ í¥ì£¼ì ',
    # --- ğŸ• ë¶„ì‹/íŒ¨ìŠ¤íŠ¸í‘¸ë“œ ---
    'ë¶„ì‹': 'ë¶„ì‹',
    'ë–¡ë³¶ì´': 'ë¶„ì‹',
    'ìˆœëŒ€': 'ë¶„ì‹',
    'êµ­ìˆ˜': 'í•œì‹',
    'ìˆ˜ì œë¹„': 'í•œì‹',
    'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ': 'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ',
    'í–„ë²„ê±°': 'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ',
    'í”¼ì': 'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ',
    'ìƒŒë“œìœ„ì¹˜': 'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ',
    'ë„ì‹œë½': 'íŒ¨ìŠ¤íŠ¸í‘¸ë“œ',
    'ê°„ì‹': 'ë¶„ì‹',
    # --- ë·”í˜ ---
    'ë¶€í˜': 'ë¶€í˜',
    'ë·”í˜': 'ë¶€í˜',
    'í•´ì‚°ë¬¼ë·”í˜': 'ë¶€í˜',
    'í•œì‹ë·”í˜': 'ë¶€í˜',
    # --- ğŸ›ï¸ ì‡¼í•‘ ë° íŒë§¤ ---
    'ì˜ë¥˜íŒë§¤': 'ì˜ë¥˜íŒë§¤',
    'ì—¬ì„±ì˜ë¥˜': 'ì˜ë¥˜íŒë§¤',
    'ì˜ë¥˜ìˆ˜ì„ ': 'ì˜ë¥˜íŒë§¤',
    'ì˜ë¥˜í• ì¸ë§¤ì¥': 'ì˜ë¥˜íŒë§¤',
    'ìƒì„¤í• ì¸ë§¤ì¥': 'ì˜ë¥˜íŒë§¤',
    'ëŒ€í˜•ë§ˆíŠ¸': 'ëŒ€í˜•ë§ˆíŠ¸',
    'ëŒ€í˜•ìŠˆí¼': 'ëŒ€í˜•ë§ˆíŠ¸',
    'ìŠˆí¼ë§ˆì¼“': 'ëŒ€í˜•ë§ˆíŠ¸',
    'ë©´ì„¸ì ': 'ì˜ë¥˜íŒë§¤',
    'ë³µí•©ì‡¼í•‘ëª°': 'ë³µí•©ì‡¼í•‘ëª°',
    'ì‹í’ˆíŒë§¤': 'ëŒ€í˜•ë§ˆíŠ¸',
    'ê°€êµ¬íŒë§¤': 'ê°€êµ¬íŒë§¤',
    'ê°€êµ¬ê±°ë¦¬': 'ê°€êµ¬íŒë§¤',
    'ì£¼ë°©ìš©í’ˆ': 'ì£¼ë°©ìš©í’ˆ',
    'ì¸í…Œë¦¬ì–´ì¥ì‹íŒë§¤': 'ì¸í…Œë¦¬ì–´ì¥ì‹íŒë§¤',
    'ì»¤íŠ¼,ë¸”ë¼ì¸ë“œíŒë§¤': 'ì¸í…Œë¦¬ì–´ì¥ì‹íŒë§¤',
    'ê½ƒì§‘,ê½ƒë°°ë‹¬': 'ê½ƒì§‘,ê½ƒë°°ë‹¬',
    'ìŒë°˜,ë ˆì½”ë“œìƒµ': 'ìŒë°˜,ë ˆì½”ë“œìƒµ',
    'ë””ìì¸ë¬¸êµ¬': 'ë””ìì¸ë¬¸êµ¬',
    'ë¬¸êµ¬,ì‚¬ë¬´ìš©í’ˆ': 'ë¬¸êµ¬,ì‚¬ë¬´ìš©í’ˆ',
    # --- ğŸ“š ì„œì  ---
    'ì„œì ': 'ì„œì ',
    'ì¤‘ê³ ì„œì ': 'ì„œì ',
    'ë…ë¦½ì„œì ': 'ì„œì ',
    # --- âš½ ì—¬ê°€/ì˜¤ë½/ê´€ê´‘ ---
    'ê²½ê¸°ê´€ëŒ': 'ê²½ê¸°ê´€ëŒ',
    'ìŠ¤í¬ì¸ /ë ˆì €': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ì¼ë°˜ìŠ¤í¬ì¸ ': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ì „ì‹œì¥': 'ì „ì‹œì¥',
    'ì „ì‹œê´€': 'ì „ì‹œì¥',
    'ë¯¸ìˆ ê´€': 'ì „ì‹œì¥',
    'ë°•ë¬¼ê´€': 'ì „ì‹œì¥',
    'ê³¼í•™ê´€': 'ì „ì‹œì¥',
    'ê¸°ë…ê´€': 'ì „ì‹œì¥',
    'ê³µì—°ì¥,ì—°ê·¹ê·¹ì¥': 'ê³µì—°ì¥,ì—°ê·¹ê·¹ì¥',
    'í…Œë§ˆíŒŒí¬': 'í…Œë§ˆíŒŒí¬',
    'í…Œë§ˆíŒŒí¬ì‹œì„¤': 'í…Œë§ˆíŒŒí¬',
    'ì•„ì¿ ì•„ë¦¬ì›€': 'í…Œë§ˆíŒŒí¬',
    'ì›Œí„°í…Œë§ˆíŒŒí¬': 'í…Œë§ˆíŒŒí¬',
    'ë™ë¬¼ì›': 'í…Œë§ˆíŒŒí¬',
    'ì‹¤ë‚´ë™ë¬¼ì›': 'í…Œë§ˆíŒŒí¬',
    'ë†€ì´ì‹œì„¤': 'í…Œë§ˆíŒŒí¬',
    'ì·¨ë¯¸/ì˜¤ë½': 'ì·¨ë¯¸/ì˜¤ë½',
    'ë¯¸ìˆ ,ê³µì˜ˆ': 'ì·¨ë¯¸/ì˜¤ë½',
    'ìŒì•…': 'ì·¨ë¯¸/ì˜¤ë½',
    'ì‚¬ì§„ê´€,í¬í† ìŠ¤íŠœë””ì˜¤': 'ì·¨ë¯¸/ì˜¤ë½',
    'ë¯¸ìˆ í•™ì›': 'ì·¨ë¯¸/ì˜¤ë½',
    'ë…¹ìŒì‹¤': 'ì·¨ë¯¸/ì˜¤ë½',
    'PCë°©': 'ì·¨ë¯¸/ì˜¤ë½',
    'ë…¸ë˜ë°©': 'ì·¨ë¯¸/ì˜¤ë½',
    'ê³µì›': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ë„ì‹œê·¼ë¦°ê³µì›': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ê³µì›ì‹œì„¤ë¬¼': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ë†€ì´í„°': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'í˜¸ìˆ˜': 'ê´€ê´‘,ëª…ì†Œ',
    'ê°•': 'ê´€ê´‘,ëª…ì†Œ',
    'í•˜ì²œ': 'ê´€ê´‘,ëª…ì†Œ',
    'ì‚°': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ë“±ì‚°ë¡œ': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ë‘˜ë ˆê¸¸': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ì•¼ì˜,ìº í•‘ì¥': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ê¸€ë¨í•‘ì¥': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ìì—°íœ´ì–‘ë¦¼': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ìì „ê±°ì—¬í–‰': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ë„ë³´ì—¬í–‰': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ì²´í—˜ì—¬í–‰': 'ìŠ¤í¬ì¸ /ë ˆì €',
    'ì •ë³´í™”,ì²´í—˜ë§ˆì„': 'ì²´í—˜ì—¬í–‰',
    'ë“œë¼ì´ë¸Œì½”ìŠ¤': 'ê´€ê´‘,ëª…ì†Œ',
    'ì´¬ì˜ì§€': 'ê´€ê´‘,ëª…ì†Œ',
    'ê´€ê´‘,ëª…ì†Œ': 'ê´€ê´‘,ëª…ì†Œ',
    # --- ğŸ¶ ë°˜ë ¤ë™ë¬¼ ---
    'ë°˜ë ¤ë™ë¬¼': 'ë°˜ë ¤ë™ë¬¼',
    'ë°˜ë ¤ë™ë¬¼ìš©í’ˆ': 'ë°˜ë ¤ë™ë¬¼',
    'ë°˜ë ¤ë™ë¬¼ë¯¸ìš©': 'ë°˜ë ¤ë™ë¬¼',
    'ë°˜ë ¤ë™ë¬¼ë¶„ì–‘': 'ë°˜ë ¤ë™ë¬¼',
    'ë°˜ë ¤ê²¬ë†€ì´í„°': 'ë°˜ë ¤ë™ë¬¼',
    # --- ğŸ¨ ìˆ™ë°• ---
    'í˜¸í…”': 'í˜¸í…”',
    'ì—¬ê´€,ëª¨í…”': 'í˜¸í…”',
    'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤': 'í˜¸í…”',
    'íœì…˜': 'íœì…˜',
    # --- ğŸ’… ë¯¸ìš© ---
    'ë¯¸ìš©': 'ë¯¸ìš©',
    'ë¯¸ìš©ì‹¤': 'ë¯¸ìš©',
    'ë„¤ì¼ìƒµ': 'ë¯¸ìš©',
    'ì²´í˜•ê´€ë¦¬': 'ë¯¸ìš©',
    # --- ê¸°íƒ€ ë¶„ë¥˜ê°€ ì• ë§¤í•˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ì¹´í…Œê³ ë¦¬ ---
    'ì§€ëª…': None,
    'nan': None,
    'ì¢…í•©ê±´ì„¤ì‚¬': None,
    'ë¹Œë¼,ì£¼íƒ': None,
    'í™”í•™': None,
    'ë†ì¥,ëª©ì¥': None,
    'ë³´ê´€,ì €ì¥': None,
    'ì›ì˜ˆì—…': None,
    'ì¶œíŒì‚¬': None,
    'ì–´ë¦°ì´ì§‘': None,
    'ëƒ‰ë‚œë°©ê¸°ì œì¡°': None,
    'ì§ì—…ì†Œê°œ,ì¸ë ¥íŒŒê²¬': None,
    'ì‚°ì—…ìš©í’ˆ': None,
    'ë¹„ì² ê¸ˆì†ì²˜ë¦¬': None,
}

# --- 3. Pydantic ì…ì¶œë ¥ ëª¨ë¸ ì •ì˜ ---
class UserPreference(BaseModel):
    gender: str
    age: int
    preferences: Dict[str, float] = Field(..., description="50ì°¨ì›ì˜ ì·¨í–¥ ë²¡í„°")
class PlannerRequest(BaseModel):
    user1: UserPreference
    user2: UserPreference
    date: str
    weather: str
    startTime: str
    endTime: str
    keywords: List[str]

    class Config:
        json_schema_extra = {
            "example": {
                "user1": {
                    "gender": "M",
                    "age": 26,
                    "preferences": {f"vec_{i}": round(0.1 * ((i-1)%10+1), 1) for i in range(1, 51)}
                },
                "user2": {
                    "gender": "F",
                    "age": 26,
                    "preferences": {f"vec_{i}": round(0.1 * ((i-1)%10+1), 1) for i in range(1, 51)}
                },
                "date": "2025-07-03",
                "weather": "ë§‘ìŒ",
                "startTime": "13:00",
                "endTime": "19:00",
                "keywords": ["ê¸°ë…ì¼", "ë¡œë§¨í‹±"]
            }
        }
class CandidateStore(BaseModel):
    store_name: str
    score: float
    similarity: float
    description: str

class LLMRecommendation(BaseModel):
    selected: str
    reason: str

class TimeSlotResult(BaseModel):
    slot: str
    top_candidates: List[CandidateStore]
    llm_recommendation: LLMRecommendation

class PlannerResponse(BaseModel):
    time_slots: List[TimeSlotResult]

# --- 4. FastAPI ì•± ì„¤ì • ë° ìì‚° ë¡œë“œ ---
app = FastAPI(title="AI Planner API v2 (Vector-based)")

@app.on_event("startup")
def load_assets():
    logger.info("--- ê°€ê²Œ DB ë° ì·¨í–¥ ë²¡í„° ë¡œë”© ì‹œì‘ ---")
    try:
        store_db = pd.read_csv(CONFIG["store_db_path"])
        store_db.dropna(subset=['latitude', 'longitude'], inplace=True)
        store_db['mapped_category'] = store_db['standard_category'].map(CATEGORY_MAPPING)
        store_db['mapped_category'] = store_db['mapped_category'].fillna(store_db['standard_category'])
        store_db = store_db[~store_db['mapped_category'].isna()]
        print('DB mapped_category ëª©ë¡:', store_db['mapped_category'].unique())
        print('DB ì „ì²´ ë°ì´í„° ê°œìˆ˜:', len(store_db))
        vec_cols = [f'vec_{i}' for i in range(1, 51)]
        assets['store_vectors'] = store_db[vec_cols].values
        assets['store_db'] = store_db
        assets['w2v_model'] = Word2Vec.load(CONFIG['w2v_model_path'])
        assets['llm_client'] = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        logger.info("--- ìì‚° ë¡œë”© ì™„ë£Œ! ---")
    except Exception as e:
        logger.error(f"ìì‚° ë¡œë”© ì˜¤ë¥˜: {e}")
        raise

# --- 5. í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---
def create_group_vector(request: PlannerRequest) -> np.ndarray:
    vec1 = np.array(list(request.user1.preferences.values()))
    vec2 = np.array(list(request.user2.preferences.values()))
    return np.mean([vec1, vec2], axis=0).reshape(1, -1)

def get_w2v_slots(group_vector: np.ndarray) -> List[Dict]:
    """w2v ëª¨ë¸ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ í™œë™ ìŠ¬ë¡¯(ì¹´í…Œê³ ë¦¬) ì¶”ì²œ"""
    w2v_model = assets['w2v_model']
    index = assets['store_db']['standard_category'].dropna().unique()
    index = list(set(index).intersection(set(w2v_model.wv.index_to_key)))
    scores = {cat: cosine_similarity(group_vector, [w2v_model.wv[cat]])[0, 0] for cat in index}
    top_cats = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]

    time_mapping = [
        ("01", "00:00", "06:59"),
        ("02", "07:00", "08:59"),
        ("03", "09:00", "10:59"),
        ("04", "11:00", "12:59"),
        ("05", "13:00", "14:59"),
        ("06", "15:00", "16:59"),
        ("07", "17:00", "18:59"),
        ("08", "19:00", "20:59"),
        ("09", "21:00", "22:59"),
        ("10", "23:00", "23:59")
    ]
    return [{"name": cat, "time_range": f"{time_start} ~ {time_end}", "category": [cat]} for (cat, _), (_, time_start, time_end) in zip(top_cats, time_mapping)]

def call_llm(candidates: List[Dict], context: Dict) -> LLMRecommendation:
    client = assets['llm_client']
    llm_input_info = ""
    for cand in candidates:
        llm_input_info += f"- ê°€ê²Œëª…: {cand['store_name']}, ì´ì : {cand['score']:.2f}, ìœ ì‚¬ë„: {cand['similarity']:.2f}, ì„¤ëª…: {cand['description']}\n"

    prompt = f"""[ëª¨ì„ ì •ë³´]
- ëª©ì : {context['meeting_purpose']}
- ë‚ ì”¨: {context['weather']}

[ì‹œìŠ¤í…œ ì¶”ì²œ í›„ë³´]
{llm_input_info}
[ë„ˆì˜ ì„ë¬´]
ìœ„ í›„ë³´ ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ê°€ê²Œ í•˜ë‚˜ë§Œ ì„ íƒí•˜ê³ , ê·¸ ì´ìœ ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
{{ "selected": "ê°€ê²Œì´ë¦„", "reason": "ì„ íƒí•œ ì´ìœ " }}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            response_format={"type": "json_object"},
            messages=[{"role": "user", "content": prompt}]
        )
        result = json.loads(response.choices[0].message.content)
        return LLMRecommendation(**result)
    except Exception as e:
        logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return LLMRecommendation(selected="ì„ íƒ ì‹¤íŒ¨", reason=str(e))

def get_time_slots(start_time_str: str, end_time_str: str) -> List[Dict]:
    """ì…ë ¥ëœ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ì— ê±¸ì¹˜ëŠ” ëª¨ë“  ì‹œê°„ëŒ€ ìŠ¬ë¡¯ì„ ë°˜í™˜"""
    
    logger.info(f"=== get_time_slots í•¨ìˆ˜ ì‹œì‘ ===")
    logger.info(f"ìš”ì²­ ì‹œê°„: {start_time_str} ~ {end_time_str}")
    
    # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¹´í…Œê³ ë¦¬ í™•ì¸
    available_categories = list(assets['store_db']['mapped_category'].unique())
    logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {available_categories}")
    
    # 13:00-19:00 ë²”ìœ„ì— ëŒ€í•´ ê°•ì œë¡œ 4ê°œ ìŠ¬ë¡¯ ìƒì„±
    slots = [
        {
            "name": "ì‹œê°„ëŒ€ 05",
            "time_range": "13:00 ~ 14:59",
            "category": ["ì»¤í”¼/ìŒë£Œ", "ì–‘ì‹", "í•œì‹"]
        },
        {
            "name": "ì‹œê°„ëŒ€ 06", 
            "time_range": "15:00 ~ 16:59",
            "category": ["ì–‘ì‹", "í•œì‹", "ì»¤í”¼/ìŒë£Œ"]
        },
        {
            "name": "ì‹œê°„ëŒ€ 07",
            "time_range": "17:00 ~ 18:59", 
            "category": ["í•œì‹", "ê³ ê¸°ìš”ë¦¬", "ì–‘ì‹"]
        },
        {
            "name": "ì‹œê°„ëŒ€ 08",
            "time_range": "19:00 ~ 19:59",
            "category": ["ê³ ê¸°ìš”ë¦¬", "í•œì‹"]
        }
    ]
    
    # ì‹¤ì œ DBì— ìˆëŠ” ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
    filtered_slots = []
    for slot in slots:
        valid_categories = [cat for cat in slot['category'] if cat in available_categories]
        if valid_categories:
            slot['category'] = valid_categories
            filtered_slots.append(slot)
            logger.info(f"ìŠ¬ë¡¯ ì¶”ê°€: {slot['time_range']}, ì¹´í…Œê³ ë¦¬: {valid_categories}")
        else:
            logger.warning(f"ìŠ¬ë¡¯ {slot['time_range']}ì— ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŒ")
    
    logger.info(f"=== get_time_slots í•¨ìˆ˜ ì¢…ë£Œ: {len(filtered_slots)}ê°œ ìŠ¬ë¡¯ ë°˜í™˜ ===")
    return filtered_slots

# API ë¼ìš°í„° ì„¤ì •
from fastapi import APIRouter
router = APIRouter(prefix="/api/v1")

@router.get("/debug-time-slots")
def debug_time_slots():
    """ì‹œê°„ëŒ€ ìŠ¬ë¡¯ ë””ë²„ê¹…ìš© ì—”ë“œí¬ì¸íŠ¸"""
    start_time = "13:00"
    end_time = "19:00"
    
    logger.info(f"DEBUG: get_time_slots í˜¸ì¶œ - {start_time} ~ {end_time}")
    slots = get_time_slots(start_time, end_time)
    logger.info(f"DEBUG: ë°˜í™˜ëœ ìŠ¬ë¡¯ ìˆ˜: {len(slots)}")
    
    return {
        "requested_time": f"{start_time} ~ {end_time}",
        "slots_count": len(slots),
        "slots": slots
    }

@router.post("/generate-plan-vector", response_model=PlannerResponse)
def generate_plan(request: PlannerRequest):
    if not assets:
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¤€ë¹„ ì¤‘")

    logger.info(f"=== API í˜¸ì¶œ ì‹œì‘ ===")
    logger.info(f"ìš”ì²­ ì‹œê°„: {request.startTime} ~ {request.endTime}")

    # ê·¸ë£¹ ë²¡í„° ìƒì„±
    group_vector = create_group_vector(request)
    logger.info(f"ê·¸ë£¹ ë²¡í„° ìƒì„± ì™„ë£Œ: shape={group_vector.shape}")
    
    # ì‹œê°„ëŒ€ë³„ ìŠ¬ë¡¯ ê°€ì ¸ì˜¤ê¸°
    logger.info("=== get_time_slots í˜¸ì¶œ ===")
    time_slots = get_time_slots(request.startTime, request.endTime)
    logger.info(f"get_time_slots ê²°ê³¼: {len(time_slots)}ê°œ ìŠ¬ë¡¯")
    for i, slot in enumerate(time_slots):
        logger.info(f"ìŠ¬ë¡¯ {i+1}: {slot}")
    
    if not time_slots:
        raise HTTPException(status_code=400, detail="ì„ íƒëœ ì‹œê°„ëŒ€ì— ë§ëŠ” ì¶”ì²œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    final_plan_slots = []
    
    # ê° ì‹œê°„ëŒ€ë³„ë¡œ ì¶”ì²œ ìƒì„±
    for slot_idx, slot in enumerate(time_slots):
        logger.info(f"=== ìŠ¬ë¡¯ {slot_idx+1}/{len(time_slots)} ì²˜ë¦¬ ì‹œì‘ ===")
        logger.info(f"Processing time slot: {slot['time_range']}")
        logger.info(f"Categories for this slot: {slot['category']}")
        
        # í•´ë‹¹ ì‹œê°„ëŒ€ì— ë§ëŠ” ì¹´í…Œê³ ë¦¬ì˜ ê°€ê²Œë“¤ë§Œ í•„í„°ë§
        candidate_stores_df = assets['store_db'][
            assets['store_db']['mapped_category'].isin(slot['category'])
        ].copy()
        
        logger.info(f"Found {len(candidate_stores_df)} stores for categories {slot['category']}")
        
        if len(candidate_stores_df) == 0:
            logger.warning(f"No stores found for categories: {slot['category']}")
            continue
            
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(
            group_vector, 
            candidate_stores_df[[f'vec_{i}' for i in range(1, 51)]].values
        ).flatten()
        
        # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        keyword_scores = np.zeros(len(candidate_stores_df))
        for keyword in request.keywords:
            # í‚¤ì›Œë“œê°€ ê°€ê²Œ ì´ë¦„ì´ë‚˜ ì„¤ëª…ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì ìˆ˜ ë¶€ì—¬
            keyword_match = candidate_stores_df['store_name'].str.contains(keyword, case=False) | \
                          candidate_stores_df['standard_category'].str.contains(keyword, case=False)
            keyword_scores += keyword_match.astype(float) * 0.2  # í‚¤ì›Œë“œë‹¹ 0.2ì 
            
        candidate_stores_df['similarity'] = similarities
        candidate_stores_df['keyword_score'] = keyword_scores
        candidate_stores_df['total_score'] = candidate_stores_df['similarity'] + candidate_stores_df['keyword_score']

        # ìƒìœ„ 3ê°œ í›„ë³´ ì„ ì •
        top_3_candidates = candidate_stores_df.nlargest(3, 'total_score')
        
        if len(top_3_candidates) == 0:
            logger.warning(f"No top candidates found for slot {slot_idx+1}")
            continue

        top_candidates_list = [
            CandidateStore(
                store_name=row['store_name'],
                score=row['total_score'],
                similarity=row['similarity'],
                description=f"{row['standard_category']} ê°€ê²Œì…ë‹ˆë‹¤."
            ) for _, row in top_3_candidates.iterrows()
        ]

        # LLMì„ í†µí•œ ìµœì¢… ì¶”ì²œ
        llm_context = {
            "meeting_purpose": ' '.join(request.keywords),
            "weather": request.weather,
            "time_slot": slot['time_range'],
            "time_name": slot['name']
        }
        llm_recommendation = call_llm(
            [c.dict() for c in top_candidates_list], 
            llm_context
        )

        # ê° ì‹œê°„ëŒ€ë³„ ê²°ê³¼ë¥¼ ì¶”ê°€
        final_plan_slots.append(
            TimeSlotResult(
                slot=slot['time_range'],  # ê° ì‹œê°„ëŒ€ì˜ ì‹¤ì œ ë²”ìœ„ ì‚¬ìš©
                top_candidates=top_candidates_list,
                llm_recommendation=llm_recommendation
            )
        )
        logger.info(f"ìŠ¬ë¡¯ {slot_idx+1} ì²˜ë¦¬ ì™„ë£Œ: {slot['time_range']}")

    if not final_plan_slots:
        raise HTTPException(
            status_code=400, 
            detail="ì„ íƒëœ ì‹œê°„ëŒ€ì— ë§ëŠ” ì¶”ì²œ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )

    logger.info(f"Generated {len(final_plan_slots)} recommendations")
    for i, slot in enumerate(final_plan_slots):
        logger.info(f"ìµœì¢… ì¶”ì²œ {i+1}: {slot.slot} -> {slot.llm_recommendation.selected}")

    # ì‹œê°„ëŒ€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
    final_plan_slots.sort(key=lambda x: datetime.strptime(x.slot.split(" ~ ")[0], "%H:%M"))

    logger.info(f"=== API í˜¸ì¶œ ì™„ë£Œ: {len(final_plan_slots)}ê°œ ìŠ¬ë¡¯ ë°˜í™˜ ===")
    return PlannerResponse(time_slots=final_plan_slots)

# ë¼ìš°í„° ë“±ë¡
app.include_router(router)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
