# íŒŒì¼ëª…: main.py (ë‹¨ë… ì‹¤í–‰ ìµœì¢…íŒ)

# --- 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
from transformers import BitsAndBytesConfig
import pandas as pd
import numpy as np
import joblib
from gensim.models import Word2Vec
from sklearn.metrics.pairwise import cosine_similarity
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import os
import datetime
import pprint
from geopy.distance import great_circle
from category_mapper import CATEGORY_MAPPING # category_mapper.pyì—ì„œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import logging
import openai
# --- 2. í”„ë¡œì íŠ¸ ì„¤ì • ë° ìì‚° ë¡œë“œ ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG = {
    "persona_vectors_path": os.path.join(BASE_DIR, "persona_vectors.npy"),
    "item_vectors_path": os.path.join(BASE_DIR, "item_vectors.npy"),
    "svd_persona_index_path": os.path.join(BASE_DIR, "svd_persona_index.pkl"),
    "svd_item_index_path": os.path.join(BASE_DIR, "svd_item_index.pkl"),
    "w2v_model_path": os.path.join(BASE_DIR, "w2v_activity_model.model"),
    "store_db_path": os.path.join(BASE_DIR, "final_store_db.csv"),}

def load_all_assets():
    """í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ëª¨ë“  ìì‚°ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    logger.info("--- ëª¨ë“  ìì‚° ë¡œë”© ì‹œì‘ ---")
    assets = {}
    try:
        # SVD/W2V ëª¨ë¸ ë° ë²¡í„° ë¡œë“œ
        persona_index = joblib.load(CONFIG["svd_persona_index_path"])
        item_index = joblib.load(CONFIG["svd_item_index_path"])
        persona_vectors = np.load(CONFIG["persona_vectors_path"])
        item_vectors = np.load(CONFIG["item_vectors_path"])
        assets['persona_vectors_df'] = pd.DataFrame(persona_vectors, index=persona_index)
        assets['item_vectors_df'] = pd.DataFrame(item_vectors, index=item_index)
        assets['w2v_model'] = Word2Vec.load(CONFIG["w2v_model_path"])
        
        # ê°€ê²Œ DB ë¡œë“œ ë° ì „ì²˜ë¦¬
        store_db = pd.read_csv(CONFIG["store_db_path"])
        store_db.dropna(subset=['latitude', 'longitude'], inplace=True)
        # 'category'ëŠ” ê°€ê²Œ DBì˜ ì›ë³¸ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ëª…ì…ë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
        store_db['standard_category'] = store_db['standard_category'].map(CATEGORY_MAPPING)
        for col in ['tag', 'positive', 'negative']:
            if col in store_db.columns:
                store_db[col] = store_db[col].astype(str).apply(lambda x: x.strip("[]").replace("'", "").split(', '))
        assets['store_db'] = store_db
            
 
        logger.info("--- ëª¨ë“  ìì‚° ë¡œë”© ì™„ë£Œ! ---")
        return assets
    except Exception as e:
        logger.error(f"ìì‚° ë¡œë”© ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

# --- 3. í•µì‹¬ ì¶”ì²œ ë¡œì§ í•¨ìˆ˜ ---
def get_final_recommendation(request, assets, openai_client):
    """
    [ìµœì¢… ì™„ì„±íŒ]
    ì‚¬ìš©ì ìš”ì²­ì„ ë°›ì•„ SVD/W2Vë¡œ í™œë™ì„ ì¶”ì²œí•˜ê³ ,
    DBì—ì„œ ì‹¤ì œ ê°€ê²Œ í›„ë³´ë¥¼ í•„í„°ë§/ì„ ì •í•˜ì—¬ OpenAI APIë¡œ ìµœì¢… ë‹µë³€ì„ ë°›ëŠ” í•¨ìˆ˜
    """
    # --- 1. ê·¸ë£¹ í˜ë¥´ì†Œë‚˜ ë²¡í„° ìƒì„± ---
    persona_vectors_df = assets['persona_vectors_df']
    group_personas = [(p['age'], p['sex']) for p in request['personas']]
    group_vector = np.mean([persona_vectors_df.loc[p].values for p in group_personas if p in persona_vectors_df.index], axis=0).reshape(1, -1)
    logger.info("âœ… ê·¸ë£¹ í˜ë¥´ì†Œë‚˜ ë²¡í„° ê³„ì‚° ì™„ë£Œ.")

    # --- 2. [í•µì‹¬ ìˆ˜ì •] ë™ì  í™œë™ ì‹œí€€ìŠ¤ ìƒì„± ---
    hour_map = {
        1: 'ìƒˆë²½', 2: 'ì•„ì¹¨', 3: 'ì˜¤ì „',
        4: 'ì ì‹¬', 5: 'ì ì‹¬', 6: 'ì˜¤í›„',
        7: 'ì˜¤í›„', 8: 'ì €ë…', 9: 'ì €ë…',
        10: 'ë°¤'
    }
    # ì…ë ¥ëœ time_slots ì½”ë“œë¥¼ 'ì˜¤í›„', 'ì €ë…' ë“± ì‹¤ì œ ì‹œê°„ëŒ€ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
    course_slots = [hour_map.get(int(slot)) for slot in request['time_slots']]
    logger.info(f"   - ìš”ì²­ëœ ì‹œê°„ ìŠ¬ë¡¯: {request['time_slots']} -> ë³€í™˜ëœ ì½”ìŠ¤: {course_slots}")
    
    activity_sequence = []
    used_categories = []
    item_vectors_df = assets['item_vectors_df']
    w2v_model = assets['w2v_model']
    previous_activity = None
    
    # ë³€í™˜ëœ ì½”ìŠ¤ ëª©ë¡ì„ ìˆœíšŒí•˜ë©° ê° ì‹œê°„ëŒ€ì— ë§ëŠ” í™œë™ì„ ì¶”ì²œ
    for i, slot_name in enumerate(course_slots):
        # í˜„ì¬ ì‹œê°„ëŒ€ì— ë§ëŠ” í›„ë³´ í™œë™ë“¤ í•„í„°ë§
        # ì´ì „ì— ì¶”ì²œëœ í™œë™ì€ ì œì™¸í•˜ì—¬ ì¤‘ë³µ ì¶”ì²œì„ ë°©ì§€
        candidate_items = item_vectors_df[
            item_vectors_df.index.str.contains(slot_name) &
            ~item_vectors_df.index.str.split('_').str[0].isin(used_categories)
        ]
        if candidate_items.empty:
            continue

        # 1) SVD ì ìˆ˜ (ê·¸ë£¹ì˜ ì •ì  ì„ í˜¸ë„)
        svd_scores = cosine_similarity(group_vector, candidate_items.values)[0]
        
        # 2) W2V ì ìˆ˜ (ì´ì „ í™œë™ê³¼ì˜ ë™ì  ì—°ê²°ì„±)
        w2v_scores = np.zeros_like(svd_scores)
        if previous_activity and previous_activity in w2v_model.wv:
            w2v_sims = {item: score for item, score in w2v_model.wv.most_similar(previous_activity, topn=len(assets['item_vectors_df']))}
            w2v_scores = np.array([w2v_sims.get(item_name, 0) for item_name in candidate_items.index])
            
        # 3) í•˜ì´ë¸Œë¦¬ë“œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
        hybrid_scores = (0.7 * svd_scores) + (0.3 * w2v_scores)
        best_activity = candidate_items.index[np.argmax(hybrid_scores)]
        activity_sequence.append(best_activity)
        used_categories.append(best_activity.split('_')[0])
        previous_activity = best_activity

    logger.info(f"âœ… SVD/W2V ë™ì  ì¶”ì²œ í™œë™: {activity_sequence}")



    # --- [í•µì‹¬ ìˆ˜ì •] Step 3 & 4: DBì—ì„œ ì‹¤ì œ ê°€ê²Œ í›„ë³´ í•„í„°ë§ ë° í”„ë¡¬í”„íŠ¸ ìƒì„± ---
    store_db = assets['store_db']
    user_loc = (request['location']['latitude'], request['location']['longitude'])

    # 1ì°¨ í•„í„°ë§: ìœ„ì¹˜ ê¸°ë°˜ (2km ë°˜ê²½)
    store_db['distance'] = store_db.apply(
        lambda row: great_circle(user_loc, (row['latitude'], row['longitude'])).km, axis=1
    )
    nearby_stores = store_db[store_db['distance'] <= 4.0].copy()
    logger.info(f"âœ… ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§ ì™„ë£Œ. í›„ë³´ {len(nearby_stores)}ê³³")

    llm_input_info = ""
    for i, activity in enumerate(activity_sequence):
        activity_category = activity.split('_')[0]
        
        # 2ì°¨ í•„í„°ë§: ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ & í‰ì ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ ì„ íƒ
        final_candidates = nearby_stores[
            nearby_stores['standard_category'] == activity_category
        ].sort_values(by='score', ascending=False).head(3)
        
        llm_input_info += f"\n### ì½”ìŠ¤ {i+1} ({activity_category}) ì¶”ì²œ í›„ë³´:\n"
        if not final_candidates.empty:
            for _, store in final_candidates.iterrows():
                # LLMì—ê²Œ ê°€ê²Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ ì „ë‹¬
                llm_input_info += (
                    f"- ê°€ê²Œëª…: {store['store_name']}\n"
                    f"  - ê±°ë¦¬: {store['distance']:.2f}km\n"
                    f"  - í‰ì : {store['score']}\n"
                    f"  - ëŒ€í‘œíƒœê·¸: {store['tag']}\n"
                    f"  - ê¸ì • í‚¤ì›Œë“œ: {store['positive']}\n"
                )
        else:
            llm_input_info += "- ì£¼ë³€ì— ì¶”ì²œí•  ë§Œí•œ ê°€ê²Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n"

    # --- Step 5: OpenAI API í˜¸ì¶œ ---
    persona_desc = f"{request['personas'][0]['age']} {len(request['personas'])}ëª… ê·¸ë£¹"
    prompt = f"""ë„ˆëŠ” ëª¨ì„ì˜ ëª©ì ê³¼ ê·¸ë£¹ì˜ íŠ¹ì§•ì— ë§ì¶° ìµœì ì˜ í•˜ë£¨ ê³„íšì„ ì§œì£¼ëŠ” AI í”Œë˜ë„ˆì•¼.

**[ëª¨ì„ ì •ë³´]**
- ê·¸ë£¹: {persona_desc}
- ëª¨ì„ ëª©ì : '{request['meeting_purpose']}'

**[ì‹œìŠ¤í…œ ì¶”ì²œ í›„ë³´ ìƒì„¸ ì •ë³´]**
{llm_input_info}

**[ë„ˆì˜ ì„ë¬´]**
1. ìœ„ 'ì‹œìŠ¤í…œ ì¶”ì²œ í›„ë³´' ëª©ë¡ì—ì„œ, ê° ì½”ìŠ¤ë³„ë¡œ ëª¨ì„ ëª©ì ê³¼ ìƒí™©ì— ê°€ì¥ ì í•©í•œ ê°€ê²Œë¥¼ **ë”± í•˜ë‚˜ì”©ë§Œ ì„ íƒ**í•´.
2. ë§Œì•½ íŠ¹ì • ì½”ìŠ¤ì— ì¶”ì²œí•  í›„ë³´ê°€ ì—†ë‹¤ë©´, ê·¸ ì½”ìŠ¤ëŠ” ê²°ê³¼ì— í¬í•¨í•˜ì§€ ë§ˆ.
3. ì•„ë˜ **'ì¶œë ¥ í˜•ì‹'ì„ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ì§€ì¼œì„œ**, ë‘ ê°œì˜ ë¶„ë¦¬ëœ ì„¹ì…˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.

**[ì¶œë ¥ í˜•ì‹]**
### âœ¨ AI ì¶”ì²œ ì½”ìŠ¤
- [ì½”ìŠ¤ 1 ì´ë¦„]: [ì„ íƒí•œ ê°€ê²Œ ì´ë¦„ 1]
- [ì½”ìŠ¤ 2 ì´ë¦„]: [ì„ íƒí•œ ê°€ê²Œ ì´ë¦„ 2]

### ğŸ“ ì¶”ì²œ ì´ìœ 
[ìœ„ì—ì„œ ê°€ê²Œë¥¼ ì„ íƒí•œ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì—¬ê¸°ì— ì¢…í•©ì ìœ¼ë¡œ ì„œìˆ ]
"""
    
    logger.info("\nâœ… ìµœì¢… í›„ë³´êµ° ì„ ì • ì™„ë£Œ. OpenAI APIì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ì‹œì‘...")
    
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[{"role": "user", "content": prompt}]
        )
        final_plan = response.choices[0].message.content
        logger.info("âœ… OpenAI APIë¡œë¶€í„° ìµœì¢… ê³„íš ìˆ˜ì‹  ì™„ë£Œ!")
        return final_plan
    except Exception as e:
        logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return "API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# --- 4. ë©”ì¸ ì‹¤í–‰ë¶€ ---
if __name__ == '__main__':
        # 1. OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("í„°ë¯¸ë„ì—ì„œ 'export OPENAI_API_KEY=\"sk-...\"' ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    else:
        client = openai.OpenAI(api_key=api_key)

        # 2. ë¡œì»¬ ìì‚°(ëª¨ë¸, ë°ì´í„°) ë¡œë“œ
        loaded_assets = load_all_assets()

        if loaded_assets:
            # 3. í…ŒìŠ¤íŠ¸í•  ì‚¬ìš©ì ìš”ì²­ ì •ì˜
            test_request_data = {
                "personas": [{"age": "20ëŒ€", "sex": "M"}],
                "location": {"latitude": 37.56, "longitude": 126.90},
                "meeting_purpose": "ì¹œêµ¬ì™€ ìŠ¤íŠ¸ë ˆìŠ¤ í’€ê¸°",
                "time_slots": ["07", "08", "09"]
            }

            # 4. ì¶”ì²œ ë¡œì§ ì‹¤í–‰
            final_recommendation = get_final_recommendation(test_request_data, loaded_assets, client)

            # 5. ìµœì¢… ê²°ê³¼ ì¶œë ¥
            print("\n\n" + "="*25)
            print("ğŸ‰ ìµœì¢… AI í”Œë˜ë„ˆ ì¶”ì²œ ê²°ê³¼ (OpenAI) ğŸ‰")
            print("="*25)
            pprint.pprint(final_recommendation)
