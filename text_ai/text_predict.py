import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import os 

# =================================================================
# 1. ë¡œì»¬ì— ì €ìž¥ëœ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸° (ìµœì¢… í•´ê²° ë²„ì „)
# =================================================================
print("âœ… ë¡œì»¬ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")

try:
    # í˜„ìž¬ ì´ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼(__file__)ì´ ìžˆëŠ” í´ë”ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    script_directory = os.path.dirname(os.path.abspath(__file__))
    
    # ê·¸ í´ë” ì•ˆì— ìžˆëŠ” 'my_best_model'ì˜ ì „ì²´ ê²½ë¡œë¥¼ ë§Œë“­ë‹ˆë‹¤.
    MODEL_PATH = os.path.join(script_directory, "my_best_model")

    # ë””ë²„ê¹…ì„ ìœ„í•´, íŒŒì´ì¬ì´ ì‹¤ì œë¡œ ì–´ë–¤ ê²½ë¡œë¥¼ ì°¾ê³  ìžˆëŠ”ì§€ ì§ì ‘ ì¶œë ¥í•´ë´…ë‹ˆë‹¤.
    print(f"ëª¨ë¸ì„ ë‹¤ìŒ ê²½ë¡œì—ì„œ ì°¾ìŠµë‹ˆë‹¤: {MODEL_PATH}")

    # í•´ë‹¹ ê²½ë¡œì— í´ë”ê°€ ì‹¤ì œë¡œ ì¡´ìž¬í•˜ëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•©ë‹ˆë‹¤.
    if not os.path.isdir(MODEL_PATH):
        raise FileNotFoundError(f"ì˜¤ë¥˜: ê³„ì‚°ëœ ê²½ë¡œì— '{MODEL_PATH}' í´ë”ê°€ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í´ë” ìœ„ì¹˜ë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
    print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")

except Exception as e:
    # ì–´ë–¤ ì˜¤ë¥˜ë“  ìƒì„¸í•˜ê²Œ ì¶œë ¥í•´ì¤ë‹ˆë‹¤.
    print(f"ðŸš¨ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    exit()


# --- ì•„ëž˜ ì½”ë“œëŠ” ì´ì „ê³¼ ë™ì¼í•©ë‹ˆë‹¤ ---

# ë¼ë²¨ ì •ë³´ (í›ˆë ¨ ì‹œ ì‚¬ìš©í–ˆë˜ ë¼ë²¨ê³¼ ìˆœì„œê°€ ê°™ì•„ì•¼ í•¨)
id_to_label = {
    0: 'ê²©ë ¤',
    1: 'ìœ„ë¡œ',
    2: 'ë™ì¡°',
    3: 'ì¡°ì–¸'
}

# =================================================================
# 2. ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
# =================================================================
def predict_empathy(text):
    device = torch.device("cpu")
    model.to(device)
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    predicted_class_id = outputs.logits.argmax().item()
    return id_to_label.get(predicted_class_id, "ì•Œ ìˆ˜ ì—†ëŠ” ë¼ë²¨")

# =================================================================
# 3. ì‚¬ìš©ìž ìž…ë ¥ë°›ì•„ ë¬´í•œ í…ŒìŠ¤íŠ¸
# =================================================================
print("\nðŸŽ‰ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì™„ë£Œ! ë¬¸ìž¥ì„ ìž…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”.")
print("   (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ìž…ë ¥í•˜ì„¸ìš”)")

while True:
    user_input = input("ìž…ë ¥ > ")
    if user_input.lower() in ["exit", "ì¢…ë£Œ"]:
        print("í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
    prediction = predict_empathy(user_input)
    print(f"ì˜ˆì¸¡ ê²°ê³¼: '{prediction}'\n")
